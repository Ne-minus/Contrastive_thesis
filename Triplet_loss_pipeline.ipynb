{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af610017-258a-4c7f-b864-47280d3c2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DataCollatorWithPadding, DefaultDataCollator\n",
    "# import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "from typing import Any, Dict, List, Literal, Union, Tuple\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, AdamW, BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from random import sample\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e4c41-fc2e-4a94-a062-588c538baf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('/raid/rabikov/contrastive_data/all_final.edgelist', create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118f830-4fab-4ac4-b442-e83c73031156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, G, tokenizer, max_length=32):\n",
    "        self.graph = G\n",
    "        self.triplets = self.sample_triplets()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Tokenize all triplets\n",
    "        self.tokenized_triplets = self.tokenize_triplets()\n",
    "\n",
    "    def sample_triplets(self):\n",
    "        triplets = []\n",
    "        for node in tqdm(self.graph.nodes()):\n",
    "            preds = list(self.graph.predecessors(node))\n",
    "            if preds:\n",
    "        \n",
    "                # print(preds)\n",
    "                positive = sample(preds, 1)[0].split('.')[0]\n",
    "            \n",
    "                flag = True\n",
    "                while flag:\n",
    "                    negative = sample(list(self.graph.nodes), 1)\n",
    "                    if negative not in preds:\n",
    "                        negative = negative[0].split('.')[0]\n",
    "                        flag = False\n",
    "                        \n",
    "                # node_new = node.split('.')[0]\n",
    "                # triplet = (f'Concept: {node_new}', f'Concept: {positive}', f'Concept: {negative}')\n",
    "                triplet = (node.split('.')[0], positive, negative)\n",
    "                triplets.append(triplet)\n",
    "            else:\n",
    "                continue\n",
    "        return triplets\n",
    "\n",
    "    def tokenize_triplets(self):\n",
    "        anchor_texts = [triplet[0] for triplet in self.triplets]\n",
    "        positive_texts = [triplet[1] for triplet in self.triplets]\n",
    "        negative_texts = [triplet[2] for triplet in self.triplets]\n",
    "\n",
    "        anchor_texts = self.tokenizer(anchor_texts, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        positive_texts = self.tokenizer(positive_texts, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        negative_texts = self.tokenizer(negative_texts, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "            \n",
    "\n",
    "        return anchor_texts, positive_texts, negative_texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'anchor_input_ids': self.tokenized_triplets[0]['input_ids'][idx],\n",
    "            'anchor_attention_mask': self.tokenized_triplets[0]['attention_mask'][idx],\n",
    "            'positive_input_ids': self.tokenized_triplets[1]['input_ids'][idx],\n",
    "            'positive_attention_mask': self.tokenized_triplets[1]['attention_mask'][idx],\n",
    "            'negative_input_ids': self.tokenized_triplets[2]['input_ids'][idx],\n",
    "            'negative_attention_mask': self.tokenized_triplets[2]['attention_mask'][idx],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ad436-1438-4ecd-b7cf-4656cd09c6ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'microsoft/MiniLM-L12-H384-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# bert = BertModel.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda:7')\n",
    "\n",
    "# device = torch.device('cuda:7') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160835a-8e63-450c-908f-2beadbf948cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('microsoft/MiniLM-L12-H384-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2843ca-0d09-4f8b-b29b-06a9d7143cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TripletDataset(G, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced3812-2efc-4a2b-9da1-a16fbe5f4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032d5ad-028a-43d5-af1d-c0f8ed3b20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa675c38-a646-48bc-aa41-5e7e85fe649a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentenceBERT(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(SentenceBERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.pooling = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # Extract the last hidden state\n",
    "        \n",
    "        # Mean pooling\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        mean_pooled_output = sum_embeddings / sum_mask\n",
    "        return mean_pooled_output\n",
    "\n",
    "sbert_model = SentenceBERT(model_name)\n",
    "device = torch.device('cuda:7') if torch.cuda.is_available() else torch.device('cpu')\n",
    "sbert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363658fb-c8d1-4eb7-b997-b2da1657085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_similarity = F.pairwise_distance(anchor, positive, p=2)\n",
    "        neg_similarity = F.pairwise_distance(anchor, negative, p=2)\n",
    "        loss = torch.mean(F.relu(self.margin + pos_similarity - neg_similarity))\n",
    "        return loss\n",
    "\n",
    "triplet_loss = TripletLoss(margin=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89969ad-107d-4311-bf98-6e21568de32f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(sbert_model.parameters(), lr=2e-5, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "num_warmup_steps = int(0.1 * num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
    "\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"contrastive_thesis_sbert_all_miniLM\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "epochs_no_improve = 0\n",
    "best_model_wts = ''\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    sbert_model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch_final = {k: v.to(device) for k, v in batch.items()}\n",
    "        # print('All on device')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Split the embeddings into anchor, positive, and negative embeddings\n",
    "        anchor_embeddings = sbert_model(batch_final['anchor_input_ids'], batch_final['anchor_attention_mask'])\n",
    "        positive_embeddings = sbert_model(batch_final['positive_input_ids'], batch_final['positive_attention_mask'])\n",
    "        negative_embeddings = sbert_model(batch_final['negative_input_ids'], batch_final['negative_attention_mask'])\n",
    "\n",
    "        loss = triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        wandb.log({'Loss': loss})\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Loss: {total_loss / len(train_dataloader)}')\n",
    "    wandb.log({'Average Training Loss': total_loss / len(train_dataloader)})\n",
    "    \n",
    "    sbert_model.eval()\n",
    "    total_eval_loss = 0\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        batch_final = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # all_embeddings = sbert_model(**batch_final)\n",
    "\n",
    "            anchor_embeddings = sbert_model(batch_final['anchor_input_ids'], batch_final['anchor_attention_mask'])\n",
    "            positive_embeddings = sbert_model(batch_final['positive_input_ids'], batch_final['positive_attention_mask'])\n",
    "            negative_embeddings = sbert_model(batch_final['negative_input_ids'], batch_final['negative_attention_mask'])\n",
    "\n",
    "            loss = triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "    print(f'Validation Loss: {total_eval_loss / len(val_dataloader)}')\n",
    "    wandb.log({'Average Validation Loss': total_eval_loss / len(val_dataloader)})\n",
    "    \n",
    "    avg_eval = total_eval_loss / len(val_dataloader)\n",
    "    if avg_eval < best_val_loss:\n",
    "        best_val_loss = avg_eval\n",
    "        best_model_wts = sbert_model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print('Early stopping')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04572d1e-cc10-4ce8-9a85-102b8f9442ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fcb77-2731-4d11-845b-c0cad5ec88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model\": sbert_model.state_dict()}, f'/raid/rabikov/contrastive_data/model/best_sbert_checkpoint_ALL_MIMLM.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf408c13-3d96-4e83-94f7-5007cdbdd7bd",
   "metadata": {},
   "source": [
    "## Test and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9f9a6-5fa8-4fb8-abca-54ee0f2e9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),  # Remove the extra dimension\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),  # Remove the extra dimension # Remove the extra dimension\n",
    "        }\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457adcf5-e443-4e9d-8149-a9002a2c77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_mag=nx.read_edgelist('./all.edgelist', create_using=nx.DiGraph, delimiter='\\t')\n",
    "all_nodes = list(G_mag.nodes())\n",
    "new_nodes = []\n",
    "\n",
    "for node in all_nodes:\n",
    "    new_nodes.append(f'Concept: {node}')\n",
    "\n",
    "tokenized = CustomDataset(new_nodes, tokenizer)\n",
    "\n",
    "dataset_mag = DataLoader(tokenized, batch_size=32)\n",
    "\n",
    "all_embedds = []\n",
    "for batch in tqdm(dataset_mag):\n",
    "    with torch.no_grad():\n",
    "        batch_final = {k: v.to(device) for k, v in batch.items()}\n",
    "        logits = sbert_model(**batch_final)\n",
    "\n",
    "\n",
    "        all_embedds.extend(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e261f-22b7-4159-b2c8-72e46d89c390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_nodes = pickle.load(open('./test_nodes.pickle', 'rb'))\n",
    "\n",
    "indices = {}\n",
    "for i, node in enumerate(all_nodes):\n",
    "    indices[node] = i\n",
    "\n",
    "matrix = {}\n",
    "for node, ans in test_nodes:\n",
    "  matrix[node] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71606232-ac85-430d-bbd0-78bf3658e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = [t.cpu() for t in all_embedds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331bee-b593-406c-a512-9dc859b1f3fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node, answer in tqdm(test_nodes):\n",
    "    node_embedding = embs[indices[node]]\n",
    "    for embedding in embs:\n",
    "        similarity = cosine_similarity(node_embedding.reshape(1,-1), embedding.reshape(1,-1))[0][0]\n",
    "        matrix[node].append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5c4e1-fd04-486f-92d5-0f835b3aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(matrix, open('sim_sbert_psy.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09672533-3171-473d-91c3-6706179250c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def default_structure():\n",
    "    return {\n",
    "        'args': np.array([]),  # Default empty numpy array\n",
    "        'nodes': [],\n",
    "        'scores': torch.tensor # Default empty list\n",
    "    }\n",
    "\n",
    "def find_top_k_indices(array, k=10):\n",
    "    # Convert the input list to a numpy array if it isn't already\n",
    "    array = np.array(array)\n",
    "    \n",
    "    # Find the indices of the elements sorted in descending order\n",
    "    sorted_indices = np.argsort(-array)\n",
    "    \n",
    "    # Take the first k elements from the sorted indices\n",
    "    top_k_indices = sorted_indices[:k]\n",
    "    \n",
    "    return top_k_indices\n",
    "\n",
    "def extract_elements(array, indices, node=None):\n",
    "    array = np.array(array)\n",
    "    extracted_elements = []\n",
    "    for idx in indices:\n",
    "        if idx < len(array):\n",
    "            if node:\n",
    "              extracted_elements.append((node, array[idx]))\n",
    "            else:\n",
    "              extracted_elements.append(array[idx])\n",
    "        else:\n",
    "            extracted_elements.append(None)  # or handle it in a way you prefer\n",
    "\n",
    "    if node:\n",
    "      return extracted_elements\n",
    "    else:\n",
    "      return torch.tensor(extracted_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda2df2-322a-4067-980f-6a70ab58e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "data = defaultdict(default_structure)\n",
    "\n",
    "for node, gold in tqdm(test_nodes):\n",
    "  args = find_top_k_indices(matrix[node], k=len(matrix[node]))[1:]\n",
    "\n",
    "  data[node]['args'] = args\n",
    "  data[node]['nodes'] = extract_elements(all_nodes, args, node)\n",
    "  data[node]['scores'] = extract_elements(matrix[node], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3232960-1392-4d17-8e1a-32bd326c7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(energy_scores, candidate_position_idx, true_position_idx):\n",
    "    tmp = np.array([[x==y for x in candidate_position_idx] for y in true_position_idx]).any(0)\n",
    "    correct = np.where(tmp)[0]\n",
    "    incorrect = np.where(~tmp)[0]\n",
    "    labels = torch.cat((torch.ones(len(correct)), torch.zeros(len(incorrect)))).int()\n",
    "    energy_scores = torch.cat((energy_scores[correct], energy_scores[incorrect]))\n",
    "    return energy_scores, labels\n",
    "\n",
    "import re\n",
    "\n",
    "def calculate_ranks_from_distance(all_distances, positive_relations):\n",
    "    \"\"\"\n",
    "    all_distances: a np array\n",
    "    positive_relations: a list of array indices\n",
    "\n",
    "    return a list\n",
    "    \"\"\"\n",
    "    # positive_relation_distance = all_distances[positive_relations]\n",
    "    # negative_relation_distance = np.ma.array(all_distances, mask=False)\n",
    "    # negative_relation_distance.mask[positive_relations] = True\n",
    "    # ranks = list((negative_relation_distance < positive_relation_distance[:, np.newaxis]).sum(axis=1) + 1)\n",
    "    # ranks = list((all_distances < positive_relation_distance[:, np.newaxis]).sum(axis=1) + 1)\n",
    "    ranks = list(np.argsort(np.argsort(all_distances))[positive_relations]+1)\n",
    "    return ranks\n",
    "\n",
    "def obtain_ranks(outputs, targets):\n",
    "    \"\"\"\n",
    "    outputs : tensor of size (batch_size, 1), required_grad = False, model predictions\n",
    "    targets : tensor of size (batch_size, ), required_grad = False, labels\n",
    "        Assume to be of format [1, 0, ..., 0, 1, 0, ..., 0, ..., 0]\n",
    "    mode == 0: rank from distance (smaller is preferred)\n",
    "    mode == 1: rank from similarity (larger is preferred)\n",
    "    \"\"\"\n",
    "    calculate_ranks = calculate_ranks_from_distance\n",
    "    all_ranks = []\n",
    "    prediction = outputs.cpu().numpy().squeeze()\n",
    "    label = targets.cpu().numpy()\n",
    "    sep = np.array([0, 1], dtype=label.dtype)\n",
    "\n",
    "    # fast way to find subarray indices in a large array, c.f. https://stackoverflow.com/questions/14890216/return-the-indexes-of-a-sub-array-in-an-array\n",
    "    end_indices = [(m.start() // label.itemsize)+1 for m in re.finditer(sep.tostring(), label.tostring())]\n",
    "    end_indices.append(len(label)+1)\n",
    "    start_indices = [0] + end_indices[:-1]\n",
    "    for start_idx, end_idx in zip(start_indices, end_indices):\n",
    "        distances = prediction[start_idx: end_idx]\n",
    "        labels = label[start_idx:end_idx]\n",
    "        positive_relations = list(np.where(labels == 1)[0])\n",
    "        ranks = calculate_ranks(distances, positive_relations)\n",
    "        all_ranks.append(ranks)\n",
    "    return all_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5ba2b-06c9-423b-8325-995f7ab64a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def macro_mr(all_ranks):\n",
    "    macro_mr = np.array([np.array(all_rank).mean() for all_rank in all_ranks]).mean()\n",
    "    return macro_mr\n",
    "\n",
    "def micro_mr(all_ranks):\n",
    "    micro_mr = np.array(list(itertools.chain(*all_ranks))).mean()\n",
    "    return micro_mr\n",
    "\n",
    "def hit_at_1(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 1)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def hit_at_3(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 3)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def hit_at_5(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 5)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def hit_at_10(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 10)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def precision_at_1(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 1)\n",
    "    return 1.0 * hits / len(all_ranks)\n",
    "\n",
    "def precision_at_3(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 3)\n",
    "    return 1.0 * hits / (len(all_ranks)*3)\n",
    "\n",
    "def precision_at_5(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 5)\n",
    "    return 1.0 * hits / (len(all_ranks)*5)\n",
    "\n",
    "def precision_at_10(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 10)\n",
    "    return 1.0 * hits / (len(all_ranks)*10)\n",
    "\n",
    "def mrr_scaled_10(all_ranks):\n",
    "    \"\"\" Scaled MRR score, check eq. (2) in the PinSAGE paper: https://arxiv.org/pdf/1806.01973.pdf\n",
    "    \"\"\"\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "\n",
    "    scaled_rank_positions = np.ceil(rank_positions / 10)\n",
    "\n",
    " #   print(scaled_rank_positions, (1.0 / scaled_rank_positions).mean())\n",
    "    return (1.0 / scaled_rank_positions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d567133-0f22-43fe-8ad4-db09aa9da24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_names = {\n",
    "    'mrr': mrr_scaled_10,\n",
    "    'p1': precision_at_1,\n",
    "    'p5': precision_at_5,\n",
    "    'r1': hit_at_1,\n",
    "    'r5': hit_at_5\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for name in metric_names.keys():\n",
    "    metrics[name] = []\n",
    "\n",
    "missing = 0\n",
    "for gold in tqdm(test_nodes):\n",
    "    query = gold[0]\n",
    "\n",
    "    gold_new = []\n",
    "    for gold_node in gold[1]:\n",
    "        gold_new.append((query, gold_node))\n",
    "\n",
    "    scores = data[query]['scores']\n",
    "    potential_nodes = data[query]['nodes']\n",
    "\n",
    "\n",
    "    # scores = torch.tensor(scores)\n",
    "    batched_energy_scores, labels = rearrange(scores, potential_nodes, gold_new)\n",
    "    # print(batched_energy_scores)\n",
    "    all_ranks = obtain_ranks(-batched_energy_scores, labels)\n",
    "\n",
    "    \n",
    "    for name, func in metric_names.items():\n",
    "        cur_metric = np.nan_to_num(func(all_ranks))\n",
    "        metrics[name].append(cur_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431afb-afed-42bc-8983-5b0eba38ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, v in metrics.items():\n",
    "    print(name, np.mean(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
